# multimodal-captioning-via-clip-gpt2
A lightweight multimodal captioning system that integrates CLIP image embeddings with GPT-2 language generation. This repository explores prompt effectiveness, semantic alignment, and entropy-weighted scoring across 1000+ image-caption pairs. Developed during PKU Summer School 2025.
